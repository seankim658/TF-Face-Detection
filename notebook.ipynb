{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "import time \n",
    "import uuid \n",
    "import cv2\n",
    "import tensorflow as tf \n",
    "import json \n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tf build info:\n",
      "OrderedDict([('cpu_compiler', 'C:/Program Files (x86)/Microsoft Visual Studio/2019/Community/VC/Tools/MSVC/14.29.30133/bin/HostX64/x64/cl.exe'), ('cuda_compute_capabilities', ['sm_35', 'sm_50', 'sm_60', 'sm_70', 'sm_75', 'compute_80']), ('cuda_version', '64_112'), ('cudart_dll_name', 'cudart64_112.dll'), ('cudnn_dll_name', 'cudnn64_8.dll'), ('cudnn_version', '64_8'), ('is_cuda_build', True), ('is_rocm_build', False), ('is_tensorrt_build', False), ('msvcp_dll_names', 'msvcp140.dll,msvcp140_1.dll'), ('nvcuda_dll_name', 'nvcuda.dll')])\n",
      "\n",
      "Device list: [PhysicalDevice(name='/physical_device:CPU:0', device_type='CPU'), PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]\n",
      "\n",
      "GPU device name: /device:GPU:0\n",
      "Tf built with cuda: True\n"
     ]
    }
   ],
   "source": [
    "# check gpu availability \n",
    "import tensorflow.python.platform.build_info as build\n",
    "print(f'Tf build info:\\n{build.build_info}\\n')\n",
    "print(f'Device list: {tf.config.list_physical_devices()}\\n')\n",
    "print(f'GPU device name: {tf.test.gpu_device_name()}')\n",
    "print(f'Tf built with cuda: {tf.test.is_built_with_cuda()}')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Collecting Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "IMAGES_PATH = os.path.join('data', 'images')\n",
    "# total images: 120\n",
    "NUM_IMGS = 20"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Capture images in batches of 20 using the laptop's webcam. Images are named using `uuid` and then saved to the images folder.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "capture = cv2.VideoCapture(0)\n",
    "for img_idx in range(NUM_IMGS):\n",
    "    ret, frame = capture.read() \n",
    "    img_name = os.path.join(IMAGES_PATH, f'{str(uuid.uuid1())}.jpg')\n",
    "    cv2.imwrite(img_name, frame)\n",
    "    cv2.imshow('frame', frame)\n",
    "    time.sleep(0.5)\n",
    "\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "capture.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Annotate images using LabelMe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "!labelme "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Limit GPU Memory Growth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "for gpu in tf.config.experimental.list_physical_devices('GPU'):\n",
    "    tf.config.experimental.set_memory_growth(gpu, True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build and Review Dataset"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Move images into train, val, and test folders. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num files: 140\n",
      "Train size: 98.0\n",
      "Val size: 21.0\n",
      "Test size: 21.0\n"
     ]
    }
   ],
   "source": [
    "# partition percentages \n",
    "TRAIN_SIZE = 0.7\n",
    "VAL_SIZE = 0.15\n",
    "TEST_SIZE = 0.15\n",
    "\n",
    "files = [f for f in os.listdir(os.path.join('data', 'images')) if os.path.isfile(os.path.join('data', 'images', f))]\n",
    "num_files = len(files)\n",
    "train_num = num_files * TRAIN_SIZE\n",
    "val_num = num_files * VAL_SIZE\n",
    "test_num = num_files * VAL_SIZE\n",
    "\n",
    "print(f'Num files: {num_files}')\n",
    "print(f'Train size: {train_num}')\n",
    "print(f'Val size: {val_num}')\n",
    "print(f'Test size: {test_num}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "# target folders \n",
    "folders = ['train', 'val', 'test']\n",
    "partitions = {folders[0]: 0, folders[1]: 0, folders[2]: 0}\n",
    "file_idx = 0\n",
    "\n",
    "while file_idx < num_files:\n",
    "\n",
    "    file = files[file_idx]\n",
    "    dest_folder = np.random.choice(a = folders, size = 1, p = [TRAIN_SIZE, VAL_SIZE, TEST_SIZE])[0]\n",
    "    curr_file_path = os.path.join('data', 'images', file)\n",
    "    new_file_path = os.path.join('data', 'images', dest_folder, file)\n",
    "\n",
    "    if dest_folder == 'train':\n",
    "        if partitions[dest_folder] < train_num:\n",
    "            os.replace(curr_file_path, new_file_path)\n",
    "            partitions[dest_folder] += 1\n",
    "        else:\n",
    "            continue \n",
    "\n",
    "    elif dest_folder == 'val': \n",
    "        if partitions[dest_folder] < val_num:\n",
    "            os.replace(curr_file_path, new_file_path)\n",
    "            partitions[dest_folder] += 1\n",
    "        else:\n",
    "            continue\n",
    "    \n",
    "    elif dest_folder == 'test':\n",
    "        if partitions[dest_folder] < test_num:\n",
    "            os.replace(curr_file_path, new_file_path)\n",
    "            partitions[dest_folder] += 1\n",
    "        else:\n",
    "            continue \n",
    "    \n",
    "    file_idx += 1"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Move matching label files into the correct train, val, and test folders. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "for folder in folders:\n",
    "    for file in os.listdir(os.path.join('data', 'images', folder)):\n",
    "        label_filename = file.split('.')[0] + '.json' \n",
    "        curr_file_path = os.path.join('data', 'labels', label_filename)\n",
    "        if os.path.exists(curr_file_path):\n",
    "            new_file_path = os.path.join('data', 'labels', folder, label_filename)\n",
    "            os.replace(curr_file_path, new_file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_image(x):\n",
    "    byte_image = tf.io.read_file(x)\n",
    "    img = tf.io.decode_jpeg(byte_image)\n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "ceef1a46cfa3b06e9010394384246b59e3f265d9615fd587d71bdb8901dad775"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
